\relax 
\citation{chellapilla2006high}
\citation{scherer2010accelerating}
\citation{strigl2010performance}
\citation{ciresan2011flexible}
\citation{MeekerReport14}
\citation{ReelSEO}
\citation{Lichtman2014big}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Diagram of all layers primitives. The red primitives are wrappers primitives provided by CuDNN. The green primitives are the novel primitives introduced in this paper.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:layers}{{1}{1}}
\citation{mathieu-iclr-14}
\citation{vasilache2014fast}
\citation{zlateski2015znn}
\citation{tschopp2015efficient}
\citation{zlateski2015znn}
\citation{ELEKTRONN2015}
\citation{matan1991multi}
\citation{sermanet2013overfeat}
\citation{jain2007supervised}
\citation{ning2005toward}
\@writefile{toc}{\contentsline {section}{\numberline {II}Throughput of sliding window inference}{2}}
\citation{giusti2013fast}
\citation{masci2013fast}
\citation{yu2015multi}
\citation{tschopp2015efficient}
\citation{zlateski2015znn}
\citation{long2015fully}
\citation{mathieu-iclr-14}
\citation{vasilache2014fast}
\citation{zlateski2015znn}
\@writefile{toc}{\contentsline {section}{\numberline {III}Pruned FFT}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Pruned FFTs. The dark blue voxels show the locations of the nonzero elements of the image after zero-padding. \relax }}{3}}
\newlabel{fig:pruned_ffts}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}General algorithm}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}CPU implementation}{3}}
\citation{frigo1999fftw}
\citation{frigo1998fftw}
\citation{nvidia2010cufft}
\citation{warren2013hacker}
\citation{bell2011thrust}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}GPU implementation}{4}}
\newlabel{sec:gpu-fft-impl}{{\unhbox \voidb@x \hbox {III-C}}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Implementation details}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Convolutional layers}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}CPU algorithms}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Relation between input and output shapes for convolutional and pooling layers, along with computational complexities. Input shape is for a batch of $S$ inputs, each of which is an $f$-tuple of 3D images with size $n^3$, and output shape is analogous. The 3D kernel has size $k^3$. The pooling window has size $p^3$, and the constant $C$ for the FFT complexity depends on the FFT implementation.\relax }}{5}}
\newlabel{table:layers_complexity}{{I}{5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Multi-core algorithm for a convolutional layer using direct convolution.\relax }}{5}}
\newlabel{alg:cpu_direct}{{1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}1}Direct convolution algorithm}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}2}Data parallel FFT-based algorithm}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}3}Task parallel FFT-based algorithm}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Memory required by different implementations. $S$ is the batch size, $f$ and $f'$ represent the number of input/output images of the layer. $n$ and $n'$ represent the number of pixels in each input/output image, and $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle n$}\mathaccent "0365{n}$ represents the number of elements in the transformed image. $K$ is pre--defined constant amount of memory allocated for cuFFT, and $T$ is the number of available cores for the CPU algorithms.\relax }}{5}}
\newlabel{table:memory_requirements}{{II}{5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Multi-core algorithm for a convolutional layer\relax }}{5}}
\newlabel{alg:cpu_fft_alg1}{{2}{5}}
\citation{jeffers2015high}
\citation{reinders2007intel}
\citation{willhalm2008putting}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Task dependency diagram of a task--based convolutional layer.\relax }}{6}}
\newlabel{fig:task_deps}{{3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}GPU implementations}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}1}Direct convolution using cuDNN}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}2}FFT based algorithm}{7}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces FFT based convolutional layer algorithm for the GPU.\relax }}{7}}
\newlabel{alg:gpu_alg}{{3}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Max-pooling and max-pooling fragments}{7}}
\citation{giusti2013fast}
\citation{masci2013fast}
\citation{giusti2013fast}
\citation{masci2013fast}
\citation{mathieu-iclr-14}
\citation{vasilache2014fast}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces ConvNet architectures of the benchmarked networks.\relax }}{8}}
\newlabel{table:benchmarked_networks}{{III}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}GPU-only or CPU-only inference}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Maximizing throughput}{8}}
\newlabel{fig:fftbatcha}{{4a}{8}}
\newlabel{sub@fig:fftbatcha}{{(a)}{a}}
\newlabel{fig:fftbatchb}{{4b}{8}}
\newlabel{sub@fig:fftbatchb}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Theoretical speedup of pooling networks using FFT--based convolution for different sizes of the inputs and different batch sizes for a network with 1 pooling layer (a) and 2 pooling layers (b).\relax }}{8}}
\newlabel{fig:fftbatch}{{4}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Maximal throughput achieved vs input image size using GPU--only and CPU--only primitives.\relax }}{9}}
\newlabel{fig:experiments1}{{5}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}Empirical results}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Optimal choice for different layers.\relax }}{9}}
\newlabel{table:gpu_optimal}{{IV}{9}}
\newlabel{fig:partial_execa}{{6a}{9}}
\newlabel{sub@fig:partial_execa}{{(a)}{a}}
\newlabel{fig:partial_execb}{{6b}{9}}
\newlabel{sub@fig:partial_execb}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Decomposing a convolutional layer into multiple convolutional sub--layers.\relax }}{9}}
\newlabel{fig:partial_exec}{{6}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}GPU + host RAM and CPU--GPU inference}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-A}}GPU + host RAM convolutional layer}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-B}}GPU + host RAM ConvNet execution}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A network of form CPCPCCCC with the first half executed one layer at the time, and the second half one batch at the time. We pooling window size of the MPF layers is $2 \times 1 \times 1$. \relax }}{10}}
\newlabel{fig:layer-vs-batch}{{8}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Maximal throughput achieved vs memory consumption using GPU--only, CPU--only, CPU + host RAM and CPU--GPU implementations for different image sizes.\relax }}{11}}
\newlabel{fig:final_results}{{7}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Comparisons to other methods.\relax }}{11}}
\newlabel{table:comparisons_to_others}{{V}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VII-C}}CPU--GPU ConvNet execution}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Comparison to other algorithms}{11}}
\citation{chetlur2014cudnn}
\citation{jia2014caffe}
\citation{tschopp2015efficient}
\citation{ELEKTRONN2015}
\citation{zlateski2015znn}
\bibcite{chellapilla2006high}{1}
\bibcite{scherer2010accelerating}{2}
\bibcite{strigl2010performance}{3}
\bibcite{ciresan2011flexible}{4}
\bibcite{MeekerReport14}{5}
\bibcite{ReelSEO}{6}
\bibcite{Lichtman2014big}{7}
\bibcite{mathieu-iclr-14}{8}
\bibcite{vasilache2014fast}{9}
\bibcite{zlateski2015znn}{10}
\bibcite{tschopp2015efficient}{11}
\bibcite{ELEKTRONN2015}{12}
\bibcite{matan1991multi}{13}
\bibcite{sermanet2013overfeat}{14}
\bibcite{jain2007supervised}{15}
\bibcite{ning2005toward}{16}
\bibcite{giusti2013fast}{17}
\bibcite{masci2013fast}{18}
\bibcite{yu2015multi}{19}
\bibcite{long2015fully}{20}
\bibcite{frigo1999fftw}{21}
\bibcite{frigo1998fftw}{22}
\bibcite{nvidia2010cufft}{23}
\bibcite{warren2013hacker}{24}
\bibcite{bell2011thrust}{25}
\bibcite{jeffers2015high}{26}
\bibcite{reinders2007intel}{27}
\bibcite{willhalm2008putting}{28}
\bibcite{chetlur2014cudnn}{29}
\bibcite{jia2014caffe}{30}
\@writefile{toc}{\contentsline {section}{References}{12}}
